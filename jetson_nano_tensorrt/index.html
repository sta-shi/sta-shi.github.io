<!DOCTYPE html>
<html lang="en-us">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
        <title>Jetson Nano TensorRT - Stashi&#39;s Blog</title><meta name="Description" content="This is Stashi&#39;s Blog"><meta property="og:title" content="Jetson Nano TensorRT" />
<meta property="og:description" content="This is a guide for TensorRT optimization." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://stashi.top/jetson_nano_tensorrt/" /><meta property="og:image" content="http://stashi.top/avatar.jpg"/><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-04-04T14:02:36+08:00" />
<meta property="article:modified_time" content="2022-04-04T00:00:00+00:00" />

<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="http://stashi.top/avatar.jpg"/>

<meta name="twitter:title" content="Jetson Nano TensorRT"/>
<meta name="twitter:description" content="This is a guide for TensorRT optimization."/>
<meta name="application-name" content="Stashi&#39;s Hollow">
<meta name="apple-mobile-web-app-title" content="Stashi&#39;s Hollow"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="http://stashi.top/jetson_nano_tensorrt/" /><link rel="prev" href="http://stashi.top/jetson_nano_ai_fundamental/" /><link rel="next" href="http://stashi.top/blog_20230626/" /><link rel="stylesheet" href="/lib/normalize/normalize.min.css"><link rel="stylesheet" href="/css/style.min.css"><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"><link rel="stylesheet" href="/lib/animate/animate.min.css"><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "Jetson Nano TensorRT",
        "inLanguage": "en-us",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "http:\/\/stashi.top\/jetson_nano_tensorrt\/"
        },"genre": "posts","keywords": "Article, Jetson Nano","wordcount":  978 ,
        "url": "http:\/\/stashi.top\/jetson_nano_tensorrt\/","datePublished": "2022-04-04T14:02:36+08:00","dateModified": "2022-04-04T00:00:00+00:00","publisher": {
            "@type": "Organization",
            "name": ""},"author": {
                "@type": "Person",
                "name": "stashi"
            },"description": ""
    }
    </script></head>
    <body header-desktop="fixed" header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="Stashi&#39;s Blog"><img
        class="lazyload logo"
        src="/svg/loading.min.svg"
        data-src="/images/menu.jpg"
        data-srcset="/images/menu.jpg, /images/menu.jpg 1.5x, /images/menu.jpg 2x"
        data-sizes="auto"
        alt="/images/menu.jpg"
        title="/images/menu.jpg" />STASHI</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/" title="All Posts"> Posts </a><a class="menu-item" href="/tags/"> Tags </a><span class="menu-item delimiter"></span><span class="menu-item search" id="search-desktop">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-desktop">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="Search">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="Clear">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-desktop">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </span><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw"></i>
                </a>
            </div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="Stashi&#39;s Blog"><img
        class="lazyload logo"
        src="/svg/loading.min.svg"
        data-src="/images/menu.jpg"
        data-srcset="/images/menu.jpg, /images/menu.jpg 1.5x, /images/menu.jpg 2x"
        data-sizes="auto"
        alt="/images/menu.jpg"
        title="/images/menu.jpg" />STASHI</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><div class="search-wrapper">
                    <div class="search mobile" id="search-mobile">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-mobile">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="Search">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="Clear">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-mobile">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </div>
                    <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
                        Cancel
                    </a>
                </div><a class="menu-item" href="/posts/" title="All Posts">Posts</a><a class="menu-item" href="/tags/" title="">Tags</a><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                <i class="fas fa-adjust fa-fw"></i>
            </a></div>
    </div>
</header>
<div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
</div>
<div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
</div>
<main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">Contents</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animated flipInX">Jetson Nano TensorRT</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="/" title="Author" rel=" author" class="author"><i class="fas fa-user-circle fa-fw"></i>stashi</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="2022-04-04">2022-04-04</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;978 words&nbsp;
                <i class="far fa-clock fa-fw"></i>&nbsp;5 minutes&nbsp;</div>
        </div><div class="featured-image"><img
        class="lazyload"
        src="/svg/loading.min.svg"
        data-src="images/Jetson_Nano_TensorRT/Cover.jpg"
        data-srcset="/images/Jetson_Nano_TensorRT/Cover.jpg, images/Jetson_Nano_TensorRT/Cover.jpg 1.5x, /images/Jetson_Nano_TensorRT/Cover.jpg 2x"
        data-sizes="auto"
        alt="/images/Jetson_Nano_TensorRT/Cover.jpg"
        title="/images/Jetson_Nano_TensorRT/Cover.jpg" /></div><div class="details toc" id="toc-static"  kept="true">
                <div class="details-summary toc-title">
                    <span>Contents</span>
                    <span><i class="details-icon fas fa-angle-right"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#overview">Overview</a></li>
    <li><a href="#convert-keras-model-to-tensorflow-model">Convert Keras Model to Tensorflow Model</a></li>
    <li><a href="#use-tensorrt-to-optimize-tensorflow-model">Use TensorRT to Optimize Tensorflow Model</a>
      <ul>
        <li><a href="#convert-tensorflow-model-to-frozen-model">Convert Tensorflow Model to Frozen Model</a></li>
        <li><a href="#optimize-frozen-model-to-tensorrt-graph">Optimize Frozen Model to TensorRT Graph</a></li>
      </ul>
    </li>
    <li><a href="#perform-inference-with-tensorrt-model">Perform Inference with TensorRT Model</a></li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><p>This is a guide for TensorRT optimization.</p>
<h2 id="overview">Overview</h2>
<figure><a class="lightgallery" href="/images/Jetson_Nano_TensorRT/Keras_to_TensorRT.jpg" title="/images/Jetson_Nano_TensorRT/Keras_to_TensorRT.jpg" data-thumbnail="/images/Jetson_Nano_TensorRT/Keras_to_TensorRT.jpg" data-sub-html="<h2>Convert Keras Model to TensorRT</h2>">
        <img
            class="lazyload"
            src="/svg/loading.min.svg"
            data-src="/images/Jetson_Nano_TensorRT/Keras_to_TensorRT.jpg"
            data-srcset="/images/Jetson_Nano_TensorRT/Keras_to_TensorRT.jpg, /images/Jetson_Nano_TensorRT/Keras_to_TensorRT.jpg 1.5x, /images/Jetson_Nano_TensorRT/Keras_to_TensorRT.jpg 2x"
            data-sizes="auto"
            alt="/images/Jetson_Nano_TensorRT/Keras_to_TensorRT.jpg" />
    </a><figcaption class="image-caption">Convert Keras Model to TensorRT</figcaption>
    </figure>
<p>Tensorflow has two versions: v1 and v2. v2 has a poor compatiblity to v1. On aurthor&rsquo;s unit the code doesn&rsquo;t work (some modules cannot be found), so I reinstalled Tensorflow 1.15.0 and re-trained the model (since Keras can&rsquo;t operate models trained by higher vesion). Also, it&rsquo;s found inconvenient to download wheel from NVIDIA download website in China. I download wheel from other device and install Tensorflow with pip3 wheel tool.</p>
<p>Furthermore, in original code by Ardian Uman, a cap is set for TensorRT, which leads to system dump. After removing it, I can optimize Tensorflow model with TensorRT and run TensorRT model as well.</p>
<p>In the process of performing inference, it&rsquo;s found that first several inferences of TensorRT model costs a rather long period that significantly influences the result. To obtain a &ldquo;seemingly reasonable&rdquo; average time, I abandoned first ten results of each model inference. Reason for the weird phenomenon remains studying.</p>
<h2 id="convert-keras-model-to-tensorflow-model">Convert Keras Model to Tensorflow Model</h2>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># import the needed libraries</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
</span></span><span class="line"><span class="cl"><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">set_learning_phase</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="c1">#use this if we have batch norm layer in our network</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">tensorflow.keras.models</span> <span class="kn">import</span> <span class="n">load_model</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># path we wanna save our converted TF-model</span>
</span></span><span class="line"><span class="cl"><span class="n">MODEL_PATH</span> <span class="o">=</span> <span class="s2">&#34;./model/TensorFlow&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># load the Keras model</span>
</span></span><span class="line"><span class="cl"><span class="n">model</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s1">&#39;./model/modelLeNet5.h5&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># save the model to Tensorflow model</span>
</span></span><span class="line"><span class="cl"><span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">sess</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">backend</span><span class="o">.</span><span class="n">get_session</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">save_path</span> <span class="o">=</span> <span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">MODEL_PATH</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Keras model is successfully converted to TF model in &#34;</span><span class="o">+</span><span class="n">MODEL_PATH</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="use-tensorrt-to-optimize-tensorflow-model">Use TensorRT to Optimize Tensorflow Model</h2>
<h3 id="convert-tensorflow-model-to-frozen-model">Convert Tensorflow Model to Frozen Model</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># import the needed libraries</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">tensorflow.contrib.tensorrt</span> <span class="k">as</span> <span class="nn">trt</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">tensorflow.python.platform</span> <span class="kn">import</span> <span class="n">gfile</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># has to be use this setting to make a session for TensorRT optimization</span>
</span></span><span class="line"><span class="cl"><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># import the meta graph of the tensorflow model</span>
</span></span><span class="line"><span class="cl">    <span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">import_meta_graph</span><span class="p">(</span><span class="s2">&#34;./model/TensorFlow.meta&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># then, restore the weights to the meta graph</span>
</span></span><span class="line"><span class="cl">    <span class="n">saver</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="s2">&#34;./model/TensorFlow&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># specify which tensor output you want to obtain </span>
</span></span><span class="line"><span class="cl">    <span class="c1"># (correspond to prediction result)</span>
</span></span><span class="line"><span class="cl">    <span class="n">your_outputs</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&#34;output_tensor/Softmax&#34;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># convert to frozen model</span>
</span></span><span class="line"><span class="cl">    <span class="n">frozen_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">graph_util</span><span class="o">.</span><span class="n">convert_variables_to_constants</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">sess</span><span class="p">,</span> <span class="c1"># session</span>
</span></span><span class="line"><span class="cl">        <span class="n">tf</span><span class="o">.</span><span class="n">get_default_graph</span><span class="p">()</span><span class="o">.</span><span class="n">as_graph_def</span><span class="p">(),</span><span class="c1"># graph+weight from the session</span>
</span></span><span class="line"><span class="cl">        <span class="n">output_node_names</span><span class="o">=</span><span class="n">your_outputs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1">#write the TensorRT model to be used later for inference</span>
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="n">gfile</span><span class="o">.</span><span class="n">FastGFile</span><span class="p">(</span><span class="s2">&#34;./model/frozen_model.pb&#34;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">frozen_graph</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Frozen model is successfully stored!&#34;</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h3 id="optimize-frozen-model-to-tensorrt-graph">Optimize Frozen Model to TensorRT Graph</h3>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># convert (optimize) frozen model to TensorRT model</span>
</span></span><span class="line"><span class="cl"><span class="n">trt_graph</span> <span class="o">=</span> <span class="n">trt</span><span class="o">.</span><span class="n">create_inference_graph</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">    <span class="n">input_graph_def</span><span class="o">=</span><span class="n">frozen_graph</span><span class="p">,</span><span class="c1"># frozen model</span>
</span></span><span class="line"><span class="cl">    <span class="n">outputs</span><span class="o">=</span><span class="n">your_outputs</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">    <span class="n">max_batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="c1"># specify your max batch size</span>
</span></span><span class="line"><span class="cl">    <span class="n">max_workspace_size_bytes</span><span class="o">=</span><span class="mi">2</span><span class="o">*</span><span class="p">(</span><span class="mi">10</span><span class="o">**</span><span class="mi">9</span><span class="p">),</span><span class="c1"># specify the max workspace</span>
</span></span><span class="line"><span class="cl">    <span class="n">precision_mode</span><span class="o">=</span><span class="s2">&#34;FP32&#34;</span><span class="p">)</span> <span class="c1"># precision, can be &#34;FP32&#34; (32 floating point precision) or &#34;FP16&#34;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">#write the TensorRT model to be used later for inference</span>
</span></span><span class="line"><span class="cl"><span class="k">with</span> <span class="n">gfile</span><span class="o">.</span><span class="n">FastGFile</span><span class="p">(</span><span class="s2">&#34;./model/TensorRT_model.pb&#34;</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">trt_graph</span><span class="o">.</span><span class="n">SerializeToString</span><span class="p">())</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;TensorRT model is successfully stored!&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">all_nodes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">([</span><span class="mi">1</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">frozen_graph</span><span class="o">.</span><span class="n">node</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;numb. of all_nodes in frozen graph:&#34;</span><span class="p">,</span> <span class="n">all_nodes</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">trt_engine_nodes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">([</span><span class="mi">1</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">trt_graph</span><span class="o">.</span><span class="n">node</span> <span class="k">if</span> <span class="nb">str</span><span class="p">(</span><span class="n">n</span><span class="o">.</span><span class="n">op</span><span class="p">)</span> <span class="o">==</span> <span class="s1">&#39;TRTEngineOp&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;numb. of trt_engine_nodes in TensorRT graph:&#34;</span><span class="p">,</span> <span class="n">trt_engine_nodes</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">all_nodes</span> <span class="o">=</span> <span class="nb">len</span><span class="p">([</span><span class="mi">1</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">trt_graph</span><span class="o">.</span><span class="n">node</span><span class="p">])</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;numb. of all_nodes in TensorRT graph:&#34;</span><span class="p">,</span> <span class="n">all_nodes</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><h2 id="perform-inference-with-tensorrt-model">Perform Inference with TensorRT Model</h2>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span><span class="lnt">42
</span><span class="lnt">43
</span><span class="lnt">44
</span><span class="lnt">45
</span><span class="lnt">46
</span><span class="lnt">47
</span><span class="lnt">48
</span><span class="lnt">49
</span><span class="lnt">50
</span><span class="lnt">51
</span><span class="lnt">52
</span><span class="lnt">53
</span><span class="lnt">54
</span><span class="lnt">55
</span><span class="lnt">56
</span><span class="lnt">57
</span><span class="lnt">58
</span><span class="lnt">59
</span><span class="lnt">60
</span><span class="lnt">61
</span><span class="lnt">62
</span><span class="lnt">63
</span><span class="lnt">64
</span><span class="lnt">65
</span><span class="lnt">66
</span><span class="lnt">67
</span><span class="lnt">68
</span><span class="lnt">69
</span><span class="lnt">70
</span><span class="lnt">71
</span><span class="lnt">72
</span><span class="lnt">73
</span><span class="lnt">74
</span><span class="lnt">75
</span><span class="lnt">76
</span><span class="lnt">77
</span><span class="lnt">78
</span><span class="lnt">79
</span><span class="lnt">80
</span><span class="lnt">81
</span><span class="lnt">82
</span><span class="lnt">83
</span><span class="lnt">84
</span><span class="lnt">85
</span><span class="lnt">86
</span><span class="lnt">87
</span><span class="lnt">88
</span><span class="lnt">89
</span><span class="lnt">90
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># import the needed libraries</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">tensorflow.contrib.tensorrt</span> <span class="k">as</span> <span class="nn">trt</span> <span class="c1"># must import this although we will not use it explicitly</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">tensorflow.python.platform</span> <span class="kn">import</span> <span class="n">gfile</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">time</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># read the testing images (only for example)</span>
</span></span><span class="line"><span class="cl"><span class="n">img1</span><span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">&#34;dataset/mnist/testing/0/test3_0.jpg&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">img2</span><span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="s2">&#34;dataset/mnist/testing/1/test2_1.jpg&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">img1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">img1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">img2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">img2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">input_img</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">img1</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">img2</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">1</span><span class="p">))),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># function to read a &#34;.pb&#34; model </span>
</span></span><span class="line"><span class="cl"><span class="c1"># (can be used to read frozen model or TensorRT model)</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">read_pb_graph</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">  <span class="k">with</span> <span class="n">gfile</span><span class="o">.</span><span class="n">FastGFile</span><span class="p">(</span><span class="n">model</span><span class="p">,</span><span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">graph_def</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">GraphDef</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">graph_def</span><span class="o">.</span><span class="n">ParseFromString</span><span class="p">(</span><span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">  <span class="k">return</span> <span class="n">graph_def</span>
</span></span><span class="line"><span class="cl">  
</span></span><span class="line"><span class="cl"><span class="c1"># perform inference</span>
</span></span><span class="line"><span class="cl"><span class="c1"># original model</span>
</span></span><span class="line"><span class="cl"><span class="n">FROZEN_MODEL_PATH</span> <span class="o">=</span> <span class="s1">&#39;./model/frozen_model.pb&#39;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="k">with</span> <span class="n">graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># read frozen model</span>
</span></span><span class="line"><span class="cl">        <span class="n">trt_graph</span> <span class="o">=</span> <span class="n">read_pb_graph</span><span class="p">(</span><span class="n">FROZEN_MODEL_PATH</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># obtain the corresponding input-output tensor</span>
</span></span><span class="line"><span class="cl">        <span class="n">tf</span><span class="o">.</span><span class="n">import_graph_def</span><span class="p">(</span><span class="n">trt_graph</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="nb">input</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;input_tensor_input:0&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">output</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;output_tensor/Softmax:0&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># in this case, it demonstrates to perform inference for 50 times</span>
</span></span><span class="line"><span class="cl">        <span class="n">total_time</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">n_time_inference</span> <span class="o">=</span> <span class="mi">100</span>
</span></span><span class="line"><span class="cl">        <span class="n">out_pred</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="nb">input</span><span class="p">:</span> <span class="n">input_img</span><span class="p">})</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_time_inference</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="n">out_pred</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="nb">input</span><span class="p">:</span> <span class="n">input_img</span><span class="p">})</span>
</span></span><span class="line"><span class="cl">            <span class="n">t2</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="n">delta_time</span> <span class="o">=</span> <span class="n">t2</span> <span class="o">-</span> <span class="n">t1</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">i</span><span class="o">&gt;</span><span class="mi">9</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">               <span class="n">total_time</span> <span class="o">+=</span> <span class="n">delta_time</span>
</span></span><span class="line"><span class="cl">            <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Needed time in inference &#34;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&#34;: &#34;</span><span class="p">,</span> <span class="n">delta_time</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">avg_time_original_model</span> <span class="o">=</span> <span class="n">total_time</span> <span class="o">/</span> <span class="p">(</span><span class="n">n_time_inference</span><span class="o">-</span><span class="mi">10</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Average inference time: &#34;</span><span class="p">,</span> <span class="n">avg_time_original_model</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># TensorRT model</span>
</span></span><span class="line"><span class="cl"><span class="n">TENSORRT_MODEL_PATH</span> <span class="o">=</span> <span class="s1">&#39;./model/TensorRT_model.pb&#39;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="k">with</span> <span class="n">graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># read TensorRT model</span>
</span></span><span class="line"><span class="cl">        <span class="n">trt_graph</span> <span class="o">=</span> <span class="n">read_pb_graph</span><span class="p">(</span><span class="n">TENSORRT_MODEL_PATH</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># obtain the corresponding input-output tensor</span>
</span></span><span class="line"><span class="cl">        <span class="n">tf</span><span class="o">.</span><span class="n">import_graph_def</span><span class="p">(</span><span class="n">trt_graph</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="nb">input</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;input_tensor_input:0&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">output</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;output_tensor/Softmax:0&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># in this case, it demonstrates to perform inference for 50 times</span>
</span></span><span class="line"><span class="cl">        <span class="n">total_time</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">n_time_inference</span> <span class="o">=</span> <span class="mi">100</span>
</span></span><span class="line"><span class="cl">        <span class="n">out_pred</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="nb">input</span><span class="p">:</span> <span class="n">input_img</span><span class="p">})</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_time_inference</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="n">out_pred</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="nb">input</span><span class="p">:</span> <span class="n">input_img</span><span class="p">})</span>
</span></span><span class="line"><span class="cl">            <span class="n">t2</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="n">delta_time</span> <span class="o">=</span> <span class="n">t2</span> <span class="o">-</span> <span class="n">t1</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">i</span><span class="o">&gt;</span><span class="mi">9</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">               <span class="n">total_time</span> <span class="o">+=</span> <span class="n">delta_time</span>
</span></span><span class="line"><span class="cl">            <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Needed time in inference &#34;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&#34;: &#34;</span><span class="p">,</span> <span class="n">delta_time</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">avg_time_tensorRT</span> <span class="o">=</span> <span class="n">total_time</span> <span class="o">/</span> <span class="p">(</span><span class="n">n_time_inference</span><span class="o">-</span><span class="mi">10</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;Average inference time: &#34;</span><span class="p">,</span> <span class="n">avg_time_tensorRT</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;TensorRT improvement compared to the original model:&#34;</span><span class="p">,</span> <span class="n">avg_time_original_model</span><span class="o">/</span><span class="n">avg_time_tensorRT</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="s1">&#39;img 1&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img1</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;pred: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">out_pred</span><span class="p">[</span><span class="mi">0</span><span class="p">])),</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">22</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="s1">&#39;img 2&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img2</span><span class="p">,</span><span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;pred: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">out_pred</span><span class="p">[</span><span class="mi">1</span><span class="p">])),</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">22</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></span></code></pre></td></tr></table>
</div>
</div></div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>Updated on 2022-04-04</span>
            </div>
            <div class="post-info-license"></div>
        </div>
        <div class="post-info-line">
            <div class="post-info-md"></div>
            <div class="post-info-share">
                <span><a href="javascript:void(0);" title="Share on Twitter" data-sharer="twitter" data-url="http://stashi.top/jetson_nano_tensorrt/" data-title="Jetson Nano TensorRT" data-hashtags="Article,Jetson Nano"><i class="fab fa-twitter fa-fw"></i></a><a href="javascript:void(0);" title="Share on Facebook" data-sharer="facebook" data-url="http://stashi.top/jetson_nano_tensorrt/" data-hashtag="Article"><i class="fab fa-facebook-square fa-fw"></i></a><a href="javascript:void(0);" title="Share on " data-sharer="weibo" data-url="http://stashi.top/jetson_nano_tensorrt/" data-title="Jetson Nano TensorRT" data-image="images/Jetson_Nano_TensorRT/Cover.jpg"><i class="fab fa-weibo fa-fw"></i></a><a href="javascript:void(0);" title="Share on Evernote" data-sharer="evernote" data-url="http://stashi.top/jetson_nano_tensorrt/" data-title="Jetson Nano TensorRT"><i class="fab fa-evernote fa-fw"></i></a></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw"></i>&nbsp;<a href="/tags/article/">Article</a>,&nbsp;<a href="/tags/jetson-nano/">Jetson Nano</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">Back</a></span>&nbsp;|&nbsp;<span><a href="/">Home</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/jetson_nano_ai_fundamental/" class="prev" rel="prev" title="Jetson Nano AI Fundamental"><i class="fas fa-angle-left fa-fw"></i>Jetson Nano AI Fundamental</a>
            <a href="/blog_20230626/" class="next" rel="next" title="2023.6.26 ">2023.6.26 <i class="fas fa-angle-right fa-fw"></i></a></div>
</div>
</article></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line">On the Boulevard of Broken Dreams</div><div class="footer-line"><i class="far fa-copyright fa-fw"></i><span itemprop="copyrightYear">2022 - 2023</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="/" target="_blank">stashi</a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="Back to Top">
                <i class="fas fa-arrow-up fa-fw"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="View Comments">
                <i class="fas fa-comment fa-fw"></i>
            </a>
        </div><link rel="stylesheet" href="/lib/katex/katex.min.css"><link rel="stylesheet" href="/lib/katex/copy-tex.min.css"><link rel="stylesheet" href="/lib/cookieconsent/cookieconsent.min.css"><script type="text/javascript" src="/lib/smooth-scroll/smooth-scroll.min.js"></script><script type="text/javascript" src="/lib/autocomplete/autocomplete.min.js"></script><script type="text/javascript" src="/lib/lunr/lunr.min.js"></script><script type="text/javascript" src="/lib/lazysizes/lazysizes.min.js"></script><script type="text/javascript" src="/lib/clipboard/clipboard.min.js"></script><script type="text/javascript" src="/lib/sharer/sharer.min.js"></script><script type="text/javascript" src="/lib/katex/katex.min.js"></script><script type="text/javascript" src="/lib/katex/auto-render.min.js"></script><script type="text/javascript" src="/lib/katex/copy-tex.min.js"></script><script type="text/javascript" src="/lib/katex/mhchem.min.js"></script><script type="text/javascript" src="/lib/cookieconsent/cookieconsent.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":50},"comment":{},"cookieconsent":{"content":{"dismiss":"Got it!","link":"Learn more","message":"This website uses Cookies to improve your experience."},"enable":true,"palette":{"button":{"background":"#f0f0f0"},"popup":{"background":"#1aa3ff"}},"theme":"edgeless"},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"highlightTag":"em","lunrIndexURL":"/index.json","maxResultLength":10,"noResultsFound":"No results found","snippetLength":50,"type":"lunr"}};</script><script type="text/javascript" src="/js/theme.min.js"></script></body>
</html>

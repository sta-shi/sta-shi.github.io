[{"categories":null,"content":"This is a guide for TensorRT optimization. ","date":"2022-04-04","objectID":"/jetson_nano_tensorrt/:0:0","tags":["Article","Jetson Nano"],"title":"Jetson Nano TensorRT","uri":"/jetson_nano_tensorrt/"},{"categories":null,"content":"Convert Keras Model to Tensorflow Model # import the needed libraries import tensorflow as tf tf.keras.backend.set_learning_phase(0) #use this if we have batch norm layer in our network from tensorflow.keras.models import load_model # path we wanna save our converted TF-model MODEL_PATH = \"./model\" # load the Keras model model = load_model('./model/modelLeNet5.h5') # save the model to Tensorflow model saver = tf.train.Saver() sess = tf.keras.backend.get_session() save_path = saver.save(sess, MODEL_PATH) print(\"Keras model is successfully converted to TF model in \"+MODEL_PATH) ","date":"2022-04-04","objectID":"/jetson_nano_tensorrt/:1:0","tags":["Article","Jetson Nano"],"title":"Jetson Nano TensorRT","uri":"/jetson_nano_tensorrt/"},{"categories":null,"content":"Use TensorRT to Optimize Tensorflow Model ","date":"2022-04-04","objectID":"/jetson_nano_tensorrt/:2:0","tags":["Article","Jetson Nano"],"title":"Jetson Nano TensorRT","uri":"/jetson_nano_tensorrt/"},{"categories":null,"content":"Convert Tensorflow Model to Frozen Model # import the needed libraries import tensorflow as tf import tensorflow.contrib.tensorrt as trt from tensorflow.python.platform import gfile # has to be use this setting to make a session for TensorRT optimization with tf.Session as sess: # import the meta graph of the tensorflow model saver = tf.train.import_meta_graph(\"./model/modelLeNet5.meta\") # then, restore the weights to the meta graph saver.restore(sess, \"./model/modelLeNet5\") # specify which tensor output you want to obtain # (correspond to prediction result) your_outputs = [\"output_tensor/Softmax\"] # convert to frozen model frozen_graph = tf.graph_util.convert_variables_to_constants( sess, # session tf.get_default_graph().as_graph_def(),# graph+weight from the session output_node_names=your_outputs) #write the TensorRT model to be used later for inference with gfile.FastGFile(\"./model/frozen_model.pb\", 'wb') as f: f.write(frozen_graph.SerializeToString()) print(\"Frozen model is successfully stored!\") ","date":"2022-04-04","objectID":"/jetson_nano_tensorrt/:2:1","tags":["Article","Jetson Nano"],"title":"Jetson Nano TensorRT","uri":"/jetson_nano_tensorrt/"},{"categories":null,"content":"Optimize Frozen Model to TensorRT Graph # convert (optimize) frozen model to TensorRT model trt_graph = trt.create_inference_graph( input_graph_def=frozen_graph,# frozen model outputs=your_outputs, max_batch_size=2,# specify your max batch size max_workspace_size_bytes=2*(10**9),# specify the max workspace precision_mode=\"FP32\") # precision, can be \"FP32\" (32 floating point precision) or \"FP16\" #write the TensorRT model to be used later for inference with gfile.FastGFile(\"./model/TensorRT_model.pb\", 'wb') as f: f.write(trt_graph.SerializeToString()) print(\"TensorRT model is successfully stored!\") ","date":"2022-04-04","objectID":"/jetson_nano_tensorrt/:2:2","tags":["Article","Jetson Nano"],"title":"Jetson Nano TensorRT","uri":"/jetson_nano_tensorrt/"},{"categories":null,"content":"Perform Inference with TensorRT Model # import the needed libraries import tensorflow as tf import tensorflow.contrib.tensorrt as trt # must import this although we will not use it explicitly from tensorflow.python.platform import gfile from PIL import Image import numpy as np import time from matplotlib import pyplot as plt # read the testing images (only for example) img1= Image.open(\"dataset/mnist/testing/0/img_108.jpg\") img2= Image.open(\"dataset/mnist/testing/1/img_0.jpg\") img1 = np.asarray(img1) img2 = np.asarray(img2) input_img = np.concatenate((img1.reshape((1, 28, 28, 1)), img2.reshape((1, 28, 28, 1))), axis=0) # function to read a \".pb\" model # (can be used to read frozen model or TensorRT model) def read_pb_graph(model): with gfile.FastGFile(model,'rb') as f: graph_def = tf.GraphDef() graph_def.ParseFromString(f.read()) return graph_def # perform inference # variable TENSORRT_MODEL_PATH = './model/TensorRT_model.pb' graph = tf.Graph() with graph.as_default(): with tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(per_process_gpu_memory_fraction=0.50))) as sess: # read TensorRT model trt_graph = read_pb_graph(TENSORRT_MODEL_PATH) # obtain the corresponding input-output tensor tf.import_graph_def(trt_graph, name='') input = sess.graph.get_tensor_by_name('input_tensor_input:0') output = sess.graph.get_tensor_by_name('output_tensor/Softmax:0') # in this case, it demonstrates to perform inference for 50 times total_time = 0; n_time_inference = 50 out_pred = sess.run(output, feed_dict={input: input_img}) for i in range(n_time_inference): t1 = time.time() out_pred = sess.run(output, feed_dict={input: input_img}) t2 = time.time() delta_time = t2 - t1 total_time += delta_time print(\"needed time in inference-\" + str(i) + \": \", delta_time) avg_time_tensorRT = total_time / n_time_inference print(\"average inference time: \", avg_time_tensorRT) ","date":"2022-04-04","objectID":"/jetson_nano_tensorrt/:3:0","tags":["Article","Jetson Nano"],"title":"Jetson Nano TensorRT","uri":"/jetson_nano_tensorrt/"},{"categories":null,"content":"This is a guide for training and performing inference on Jetson Nano. ","date":"2022-03-10","objectID":"/jetson_nano_ai_fundamental/:0:0","tags":["Article","Jetson Nano"],"title":"Jetson Nano AI Fundamental","uri":"/jetson_nano_ai_fundamental/"},{"categories":null,"content":"Use ImageNet on Jetson git clone --recursive https://github.com/dusty-nv/jetson-inference cd jetson-inference docker/run.sh # Click OK to download pre-trained models #docker cd build/aarch64/bin ./imagenet \"images/object_*.jpg\" \"images/test/object_%i.jpg\" ./imagenet \"images/cat_*.jpg\" \"images/test/cat_%i.jpg\" ","date":"2022-03-10","objectID":"/jetson_nano_ai_fundamental/:1:0","tags":["Article","Jetson Nano"],"title":"Jetson Nano AI Fundamental","uri":"/jetson_nano_ai_fundamental/"},{"categories":null,"content":"Train Keras Model and Perform Inference Download and extract four .gz files from MNIST Database. ","date":"2022-03-10","objectID":"/jetson_nano_ai_fundamental/:2:0","tags":["Article","Jetson Nano"],"title":"Jetson Nano AI Fundamental","uri":"/jetson_nano_ai_fundamental/"},{"categories":null,"content":"Convert MNIST ubyte to Images Please create folders like ‘./dataset/mnist/training/0’ in advance. import numpy as np import cv2 import os import struct def save_mnist_to_jpg(mnist_image_file, mnist_label_file, save_dir): if 'train' in os.path.basename(mnist_image_file): prefix = 'train' else: prefix = 'test' labelIndex = 0 imageIndex = 0 i = 0 lbdata = open(mnist_label_file, 'rb').read() magic, nums = struct.unpack_from(\"\u003eII\", lbdata, labelIndex) labelIndex += struct.calcsize('\u003eII') imgdata = open(mnist_image_file, \"rb\").read() magic, nums, numRows, numColumns = struct.unpack_from('\u003eIIII', imgdata, imageIndex) imageIndex += struct.calcsize('\u003eIIII') for i in range(nums): label = struct.unpack_from('\u003eB', lbdata, labelIndex)[0] labelIndex += struct.calcsize('\u003eB') im = struct.unpack_from('\u003e784B', imgdata, imageIndex) imageIndex += struct.calcsize('\u003e784B') im = np.array(im, dtype='uint8') img = im.reshape(28, 28) save_name = os.path.join(save_dir, '{}'.format(label), '{}{}_{}.jpg'.format(prefix, i, label)) cv2.imwrite(save_name, img) if __name__ == '__main__': train_images = './train-images-idx3-ubyte' train_labels = './train-labels-idx1-ubyte' test_images = './t10k-images-idx3-ubyte' test_labels = './t10k-labels-idx1-ubyte' save_train_dir = './dataset/mnist/training' save_test_dir = './dataset/mnist/testing' if not os.path.exists(save_train_dir): os.makedirs(save_train_dir) if not os.path.exists(save_test_dir): os.makedirs(save_test_dir) save_mnist_to_jpg(test_images, test_labels, save_test_dir) save_mnist_to_jpg(train_images, train_labels, save_train_dir) ","date":"2022-03-10","objectID":"/jetson_nano_ai_fundamental/:2:1","tags":["Article","Jetson Nano"],"title":"Jetson Nano AI Fundamental","uri":"/jetson_nano_ai_fundamental/"},{"categories":null,"content":"Read Input Images # import the needed libraries import numpy as np from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Activation from tensorflow.keras import backend as K from tensorflow.keras.preprocessing.image import ImageDataGenerator # config img_width, img_height = 28,28 #width \u0026 height of input image input_depth = 1 #1: gray image train_data_dir = './dataset/mnist/training' #data training path testing_data_dir = './dataset/mnist/testing' #data testing path epochs = 2 #number of training epoch batch_size = 5 #training batch size # define image generator for Keras, # here, we map pixel intensity to 0-1 train_datagen = ImageDataGenerator(rescale=1/255) test_datagen = ImageDataGenerator(rescale=1/255) # read image batch by batch train_generator = train_datagen.flow_from_directory( train_data_dir, color_mode='grayscale',#inpput iameg: gray target_size=(img_width,img_height),#input image size batch_size=batch_size,#batch size class_mode='categorical')#categorical: one-hot encoding format class label testing_generator = test_datagen.flow_from_directory( testing_data_dir, color_mode='grayscale', target_size=(img_width,img_height), batch_size=batch_size, class_mode='categorical') ","date":"2022-03-10","objectID":"/jetson_nano_ai_fundamental/:2:2","tags":["Article","Jetson Nano"],"title":"Jetson Nano AI Fundamental","uri":"/jetson_nano_ai_fundamental/"},{"categories":null,"content":"Define the Network # define number of filters and nodes in the fully connected layer NUMB_FILTER_L1 = 20 NUMB_FILTER_L2 = 20 NUMB_FILTER_L3 = 20 NUMB_NODE_FC_LAYER = 10 #define input image order shape if K.image_data_format() == 'channels_first': input_shape_val = (input_depth, img_width, img_height) else: input_shape_val = (img_width, img_height, input_depth) #define the network model = Sequential() # Layer 1 model.add(Conv2D(NUMB_FILTER_L1, (5, 5), input_shape=input_shape_val, padding='same', name='input_tensor')) model.add(Activation('relu')) model.add(MaxPool2D((2, 2))) # Layer 2 model.add(Conv2D(NUMB_FILTER_L2, (5, 5), padding='same')) model.add(Activation('relu')) model.add(MaxPool2D((2, 2))) # Layer 3 model.add(Conv2D(NUMB_FILTER_L3, (5, 5), padding='same')) model.add(Activation('relu')) # flattening the model for fully connected layer model.add(Flatten()) # fully connected layer model.add(Dense(NUMB_NODE_FC_LAYER, activation='relu')) # output layer model.add(Dense(train_generator.num_classes, activation='softmax', name='output_tensor')) # Compilile the network model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy']) # Show the model summary model.summary() ","date":"2022-03-10","objectID":"/jetson_nano_ai_fundamental/:2:3","tags":["Article","Jetson Nano"],"title":"Jetson Nano AI Fundamental","uri":"/jetson_nano_ai_fundamental/"},{"categories":null,"content":"Train the Network # Train and test the network model.fit_generator( train_generator,#our training generator #number of iteration per epoch = number of data / batch size steps_per_epoch=np.floor(train_generator.n/batch_size), epochs=epochs,#number of epoch validation_data=testing_generator,#our validation generator #number of iteration per epoch = number of data / batch size validation_steps=np.floor(testing_generator.n / batch_size)) ","date":"2022-03-10","objectID":"/jetson_nano_ai_fundamental/:2:4","tags":["Article","Jetson Nano"],"title":"Jetson Nano AI Fundamental","uri":"/jetson_nano_ai_fundamental/"},{"categories":null,"content":"Save the Trained Network print(\"Training is done!\") if not os.path.exists('./model'): os.makedirs('./model') model.save('./model/modelLeNet5.h5') print(\"Model is successfully stored!\") ","date":"2022-03-10","objectID":"/jetson_nano_ai_fundamental/:2:5","tags":["Article","Jetson Nano"],"title":"Jetson Nano AI Fundamental","uri":"/jetson_nano_ai_fundamental/"},{"categories":null,"content":"Perform Inference # import the needed libraries from tensorflow.keras.models import load_model from PIL import Image from matplotlib import pyplot as plt import numpy as np # read the input image using Pillow (you can use another library, e.g., OpenCV) img1= Image.open(\"dataset/mnist/testing/0/test3_0.jpg\") img2= Image.open(\"dataset/mnist/testing/1/test2_1.jpg\") # convert to ndarray numpy img1 = np.asarray(img1) img2 = np.asarray(img2) # load the trained model model = load_model('./model/modelLeNet5.h5') # predict the input image using the loaded model pred1 = model.predict_classes((img1/255).reshape((1,28,28,1))) pred2 = model.predict_classes((img2/255).reshape((1,28,28,1))) # plot the prediction result plt.figure('img1') plt.imshow(img1,cmap='gray') plt.title('pred:'+str(pred1[0]), fontsize=22) plt.figure('img2') plt.imshow(img2,cmap='gray') plt.title('pred:'+str(pred2[0]), fontsize=22) plt.show() ","date":"2022-03-10","objectID":"/jetson_nano_ai_fundamental/:2:6","tags":["Article","Jetson Nano"],"title":"Jetson Nano AI Fundamental","uri":"/jetson_nano_ai_fundamental/"},{"categories":null,"content":"Reference NVIDIA - Jetson Inference hashot - 将mnist数据集转换为JPG图片 Ardian Uman - Tenorflow-TensorRT ","date":"2022-03-10","objectID":"/jetson_nano_ai_fundamental/:3:0","tags":["Article","Jetson Nano"],"title":"Jetson Nano AI Fundamental","uri":"/jetson_nano_ai_fundamental/"},{"categories":null,"content":"This is a Quick Start for Jetson Nano. Board used in this article is Jetson Nano 2GB. ","date":"2022-03-02","objectID":"/jetson_nano_setup/:0:0","tags":["Article","Jetson Nano"],"title":"Jetson Nano Setup","uri":"/jetson_nano_setup/"},{"categories":null,"content":"Setup ","date":"2022-03-02","objectID":"/jetson_nano_setup/:1:0","tags":["Article","Jetson Nano"],"title":"Jetson Nano Setup","uri":"/jetson_nano_setup/"},{"categories":null,"content":"Overview Jetson Nano 2GB\" Jetson Nano 2GB Ports ① microSD card slot for main storage ⑥ USB 3.0 port (x1) ② 40-pin expansion header ⑦ HDMI output port ③ Micro-USB port for Device Mode ⑧ USB-C for 5V power input ④ Gigabit Ethernet port ⑨ MIPI CSI-2 camera connector ⑤ USB 2.0 ports (x2) ","date":"2022-03-02","objectID":"/jetson_nano_setup/:1:1","tags":["Article","Jetson Nano"],"title":"Jetson Nano Setup","uri":"/jetson_nano_setup/"},{"categories":null,"content":"Write Image to microSD Card Download Jetson Nano 2GB Developer Kit SD Card Image Write image to microSD with Etcher ","date":"2022-03-02","objectID":"/jetson_nano_setup/:1:2","tags":["Article","Jetson Nano"],"title":"Jetson Nano Setup","uri":"/jetson_nano_setup/"},{"categories":null,"content":"First Boot Insert the microSD card Set the developer kit on a non-conductive surface Connect monitor, keyboard, mouse and USB-C power supply (5V⎓3A) Boot and setup ","date":"2022-03-02","objectID":"/jetson_nano_setup/:1:3","tags":["Article","Jetson Nano"],"title":"Jetson Nano Setup","uri":"/jetson_nano_setup/"},{"categories":null,"content":"Change Source ","date":"2022-03-02","objectID":"/jetson_nano_setup/:2:0","tags":["Article","Jetson Nano"],"title":"Jetson Nano Setup","uri":"/jetson_nano_setup/"},{"categories":null,"content":"Change Ubuntu Source sudo nano /etc/apt/sources.list # delete all contents deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-updates main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-backports main restricted universe multiverse deb https://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-security main restricted universe multiverse ","date":"2022-03-02","objectID":"/jetson_nano_setup/:2:1","tags":["Article","Jetson Nano"],"title":"Jetson Nano Setup","uri":"/jetson_nano_setup/"},{"categories":null,"content":"Install and Change pip3 Source sudo apt install python3-pip pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple ","date":"2022-03-02","objectID":"/jetson_nano_setup/:2:2","tags":["Article","Jetson Nano"],"title":"Jetson Nano Setup","uri":"/jetson_nano_setup/"},{"categories":null,"content":"Pytorch ","date":"2022-03-02","objectID":"/jetson_nano_setup/:3:0","tags":["Article","Jetson Nano"],"title":"Jetson Nano Setup","uri":"/jetson_nano_setup/"},{"categories":null,"content":"PyTorch pip wheels Will install PyTorch v1.10.0 since the image is embedded with JetPack 4.6. ","date":"2022-03-02","objectID":"/jetson_nano_setup/:3:1","tags":["Article","Jetson Nano"],"title":"Jetson Nano Setup","uri":"/jetson_nano_setup/"},{"categories":null,"content":"Installation Install Pytorch wget https://nvidia.box.com/shared/static/fjtbno0vpo676a25cgvuqc1wty0fkkg6.whl -O torch-1.10.0-cp36-cp36m-linux_aarch64.whl sudo apt-get install python3-pip libopenblas-base libopenmpi-dev pip3 install Cython pip3 install numpy torch-1.10.0-cp36-cp36m-linux_aarch64.whl Install torchvision sudo apt-get install libjpeg-dev zlib1g-dev libpython3-dev libavcodec-dev libavformat-dev libswscale-dev git clone --branch v0.11.1 https://github.com/pytorch/vision torchvision cd torchvision export BUILD_VERSION=0.11.1 python3 setup.py install --user cd ../ ","date":"2022-03-02","objectID":"/jetson_nano_setup/:3:2","tags":["Article","Jetson Nano"],"title":"Jetson Nano Setup","uri":"/jetson_nano_setup/"},{"categories":null,"content":"Verification python3 import torch print(torch.__version__) print('CUDA available: ' + str(torch.cuda.is_available())) print('cuDNN version: ' + str(torch.backends.cudnn.version())) a = torch.cuda.FloatTensor(2).zero_() print('Tensor a = ' + str(a)) b = torch.randn(2).cuda() print('Tensor b = ' + str(b)) c = a + b print('Tensor c = ' + str(c)) import torchvision print(torchvision.__version__) ","date":"2022-03-02","objectID":"/jetson_nano_setup/:3:3","tags":["Article","Jetson Nano"],"title":"Jetson Nano Setup","uri":"/jetson_nano_setup/"},{"categories":null,"content":"Tensorflow ","date":"2022-03-02","objectID":"/jetson_nano_setup/:4:0","tags":["Article","Jetson Nano"],"title":"Jetson Nano Setup","uri":"/jetson_nano_setup/"},{"categories":null,"content":"Installation sudo apt-get update sudo apt-get install libhdf5-serial-dev hdf5-tools libhdf5-dev zlib1g-dev zip libjpeg8-dev liblapack-dev libblas-dev gfortran sudo apt-get install python3-pip pip3 install -U pip testresources setuptools==49.6.0 pip3 install -U --no-deps numpy==1.19.4 future==0.18.2 mock==3.0.5 keras_preprocessing==1.1.2 keras_applications==1.0.8 gast==0.4.0 protobuf pybind11 cython pkgconfig env H5PY_SETUP_REQUIRES=0 pip3 install -U h5py==3.1.0 # if h5py installation failed, try \"pip3 install h5py\", which will install h5py 2.10.0 pip3 install --pre --extra-index-url https://developer.download.nvidia.com/compute/redist/jp/v46 tensorflow ","date":"2022-03-02","objectID":"/jetson_nano_setup/:4:1","tags":["Article","Jetson Nano"],"title":"Jetson Nano Setup","uri":"/jetson_nano_setup/"},{"categories":null,"content":"Verification python3 import tensorflow ","date":"2022-03-02","objectID":"/jetson_nano_setup/:4:2","tags":["Article","Jetson Nano"],"title":"Jetson Nano Setup","uri":"/jetson_nano_setup/"},{"categories":null,"content":"JupyterLab ","date":"2022-03-02","objectID":"/jetson_nano_setup/:5:0","tags":["Article","Jetson Nano"],"title":"Jetson Nano Setup","uri":"/jetson_nano_setup/"},{"categories":null,"content":"Installation pip3 install jupyterlab==3 jupyter lab --generate-config ","date":"2022-03-02","objectID":"/jetson_nano_setup/:5:1","tags":["Article","Jetson Nano"],"title":"Jetson Nano Setup","uri":"/jetson_nano_setup/"},{"categories":null,"content":"Setting nano /home/jetson/.jupyter/jupyter_lab_config.py # copy to front of the file c.ServerApp.allow_remote_access = True c.ExtensionApp.open_browser = False c.ServerApp.ip = '0.0.0.0' c.ServerApp.password_required = False c.ServerApp.port = 8888 c.ServerApp.token = '' ","date":"2022-03-02","objectID":"/jetson_nano_setup/:5:2","tags":["Article","Jetson Nano"],"title":"Jetson Nano Setup","uri":"/jetson_nano_setup/"},{"categories":null,"content":"Usage jupyter lab ","date":"2022-03-02","objectID":"/jetson_nano_setup/:5:3","tags":["Article","Jetson Nano"],"title":"Jetson Nano Setup","uri":"/jetson_nano_setup/"},{"categories":null,"content":"Reference Zhihu - Jetson Nano 快速入门 NVIDIA Developer - Getting Started with Jetson Nano 2GB Developer Kit ","date":"2022-03-02","objectID":"/jetson_nano_setup/:6:0","tags":["Article","Jetson Nano"],"title":"Jetson Nano Setup","uri":"/jetson_nano_setup/"},{"categories":null,"content":"Welcome. This is the first post of my blog. Hugo Setup: Cyhour My Theme: LoveIt ","date":"2022-03-01","objectID":"/hello_world/:0:0","tags":["Blog"],"title":"Hello World","uri":"/hello_world/"}]